{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. 'Bought Together'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import NGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv data\n",
    "aisles = pd.read_csv('/Users/Nicole/Desktop/raw/aisles.csv')\n",
    "dept = pd.read_csv('/Users/Nicole/Desktop/raw/departments.csv')\n",
    "prod = pd.read_csv('/Users/Nicole/Desktop/raw/products.csv')\n",
    "train = pd.read_csv('/Users/Nicole/Desktop/raw/order_products__prior.csv')\n",
    "test = pd.read_csv('/Users/Nicole/Desktop/raw/order_products__train.csv')\n",
    "orders = pd.read_csv('/Users/Nicole/Desktop/raw/orders.csv')\n",
    "orders_clustered = pd.read_csv('/Users/Nicole/Desktop/raw/orders_clustered.csv')\n",
    "\n",
    "df = [aisles, dept, prod, train, test, orders]\n",
    "df_names = ['aisles','dept','prod','train','test','orders']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Product Bundle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Michigan Organic Kale'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge user, order and product info into one df\n",
    "order_prod = pd.merge(train,prod,on='product_id',how='left')\n",
    "user_order_prod = pd.merge(order_prod,orders,on='order_id',how='left')\n",
    "user_order_prod['product_name'][1]  ## seperated by whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Michigan_Organic_Kale'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace whitespaces with \"_\"\n",
    "products = user_order_prod['product_name']\n",
    "prod_no_space =[]\n",
    "for product in products:\n",
    "    product = product.replace(' ','_')\n",
    "    prod_no_space.append(product)\n",
    "\n",
    "# replace the original column with no_space one\n",
    "user_order_prod.drop(['product_name'],axis=1)\n",
    "user_order_prod['product_name'] = prod_no_space\n",
    "user_order_prod['product_name'][1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>department_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>33120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Organic_Egg_Whites</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>202279</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>28985</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Michigan_Organic_Kale</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>202279</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9327</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Garlic_Powder</td>\n",
       "      <td>104</td>\n",
       "      <td>13</td>\n",
       "      <td>202279</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>45918</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Coconut_Butter</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>202279</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>30035</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Natural_Sweetener</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>202279</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  product_id  add_to_cart_order  reordered           product_name  \\\n",
       "0         2       33120                  1          1     Organic_Egg_Whites   \n",
       "1         2       28985                  2          1  Michigan_Organic_Kale   \n",
       "2         2        9327                  3          0          Garlic_Powder   \n",
       "3         2       45918                  4          1         Coconut_Butter   \n",
       "4         2       30035                  5          0      Natural_Sweetener   \n",
       "\n",
       "   aisle_id  department_id  user_id eval_set  order_number  order_dow  \\\n",
       "0        86             16   202279    prior             3          5   \n",
       "1        83              4   202279    prior             3          5   \n",
       "2       104             13   202279    prior             3          5   \n",
       "3        19             13   202279    prior             3          5   \n",
       "4        17             13   202279    prior             3          5   \n",
       "\n",
       "   order_hour_of_day  days_since_prior_order  \n",
       "0                  9                     8.0  \n",
       "1                  9                     8.0  \n",
       "2                  9                     8.0  \n",
       "3                  9                     8.0  \n",
       "4                  9                     8.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_order_prod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_order_prod.to_csv('/Users/Nicole/Desktop/raw/user_order_prod.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Organic_Egg_Whites Michigan_Organic_Kale Garli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Total_2%_with_Strawberry_Lowfat_Greek_Strained...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Plain_Pre-Sliced_Bagels Honey/Lemon_Cough_Drop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Bag_of_Organic_Bananas Just_Crisp,_Parmesan Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Cleanse Dryer_Sheets_Geranium_Scent Clean_Day_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id                                           products\n",
       "0         2  Organic_Egg_Whites Michigan_Organic_Kale Garli...\n",
       "1         3  Total_2%_with_Strawberry_Lowfat_Greek_Strained...\n",
       "2         4  Plain_Pre-Sliced_Bagels Honey/Lemon_Cough_Drop...\n",
       "3         5  Bag_of_Organic_Bananas Just_Crisp,_Parmesan Fr...\n",
       "4         6  Cleanse Dryer_Sheets_Geranium_Scent Clean_Day_..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregate all products by order id\n",
    "all_prod = []\n",
    "for p_name in user_order_prod.groupby('order_id')['product_name']:\n",
    "    all_prod.append(' '.join(p_name[1]))\n",
    "\n",
    "# put the results into new df\n",
    "order_id = user_order_prod.groupby('order_id')['product_name'].agg('count').index\n",
    "order_id_prod = pd.DataFrame({'order_id':order_id,'products':all_prod})\n",
    "order_id_prod.head()  ## take a glimpse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)Extract Bigrams (PySpark)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the df in PySpark format\n",
    "df = []\n",
    "index = 0\n",
    "for row in order_id_prod['products']:\n",
    "    prod_name = row.split(' ')\n",
    "    tup = (index, prod_name)\n",
    "    df.append(tup)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly split data into train (70%) and test (30%)\n",
    "random.shuffle(df)\n",
    "train_df = df[:2250411]\n",
    "test_df = df[2250411:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to spark df\n",
    "spark = SparkSession.builder.appName(\"Bigram\").getOrCreate()\n",
    "\n",
    "# read 10,000 lines each time to reduce computation\n",
    "N = len(train_df)//10000\n",
    "mod = len(train_df) % 10000\n",
    "trainDF = spark.createDataFrame(df[0:10000], ['id',\"product_name\"])\n",
    "\n",
    "for i in range(1,N):\n",
    "    trainDF_sub = spark.createDataFrame(train_df[10000*i:10000*(i+1)], ['id',\"product_name\"])\n",
    "    traintDF = trainDF.union(trainDF_sub)\n",
    "\n",
    "# combine into one spark df \n",
    "trainDF_sub = spark.createDataFrame(train_df[10000*N:len(train_df)], ['id',\"product_name\"])\n",
    "trainDF = trainDF.union(trainDF_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect bigrams\n",
    "ngram = NGram(n=2, inputCol=\"product_name\", outputCol=\"bigrams\")\n",
    "ngram_df = ngram.transform(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count frequency\n",
    "bigrams = ngram_df.toPandas()['bigrams']\n",
    "table = {}\n",
    "total = len(bigrams)\n",
    "completion = 0\n",
    "for bigram in bigrams:\n",
    "    for combination in bigram:\n",
    "        components = combination.split(' ')\n",
    "        key = components[0]\n",
    "        valKey = components[1]\n",
    "        if key in table:\n",
    "            valueDict = table[key]\n",
    "            if valKey in valueDict:\n",
    "                valueDict[valKey] = valueDict[valKey] + 1\n",
    "            else:\n",
    "                valueDict[valKey] = 1\n",
    "        else:\n",
    "            # create new value for key\n",
    "            valueDict =  {valKey: 1}\n",
    "            table[key] = valueDict\n",
    "    completion += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banana & Organic_Avocado , 22\n",
      "Banana & Strawberries , 21\n",
      "Banana & Organic_Fuji_Apple , 24\n",
      "Banana & Large_Lemon , 21\n",
      "Organic_Strawberries & Bag_of_Organic_Bananas , 21\n",
      "Bag_of_Organic_Bananas & Organic_Hass_Avocado , 27\n",
      "Bag_of_Organic_Bananas & Organic_Strawberries , 27\n",
      "Bag_of_Organic_Bananas & Organic_Raspberries , 21\n",
      "Organic_Baby_Spinach & Banana , 21\n",
      "Organic_Hass_Avocado & Bag_of_Organic_Bananas , 21\n"
     ]
    }
   ],
   "source": [
    "# product combinations appears more than 20 times\n",
    "for firstWord in table:\n",
    "    for secondWord in table[firstWord]:\n",
    "        if table[firstWord][secondWord] > 20:\n",
    "            print(firstWord, \"&\", secondWord, \",\", table[firstWord][secondWord])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banana & Organic_Baby_Spinach , 17\n",
      "Banana & Organic_Strawberries , 17\n",
      "Banana & Cucumber_Kirby , 15\n",
      "Banana & Organic_Hass_Avocado , 12\n",
      "Organic_Strawberries & Organic_Baby_Spinach , 12\n",
      "Organic_Strawberries & Banana , 15\n",
      "Organic_Strawberries & Organic_Blueberries , 15\n",
      "Organic_Strawberries & Organic_Raspberries , 16\n",
      "Bag_of_Organic_Bananas & Organic_Whole_Milk , 14\n",
      "Bag_of_Organic_Bananas & Organic_Baby_Spinach , 11\n",
      "Organic_Baby_Spinach & Bag_of_Organic_Bananas , 15\n",
      "Organic_Hass_Avocado & Organic_Strawberries , 14\n",
      "Organic_Hass_Avocado & Organic_Raspberries , 14\n",
      "Organic_Hass_Avocado & Organic_Baby_Spinach , 11\n",
      "Organic_Hass_Avocado & Banana , 13\n",
      "Organic_Raspberries & Bag_of_Organic_Bananas , 13\n",
      "Organic_Raspberries & Organic_Strawberries , 17\n",
      "Strawberries & Banana , 11\n",
      "Strawberries & Blueberries , 14\n",
      "Large_Lemon & Banana , 14\n",
      "Organic_Yellow_Onion & Organic_Garlic , 14\n",
      "Organic_Cucumber & Organic_Hass_Avocado , 12\n",
      "Organic_Cilantro & Limes , 15\n",
      "Limes & Large_Lemon , 15\n",
      "Organic_Zucchini & Organic_Yellow_Squash , 13\n",
      "Organic_Blueberries & Organic_Strawberries , 11\n",
      "Raspberries & Strawberries , 13\n",
      "Sparkling_Water_Grapefruit & Lime_Sparkling_Water , 14\n"
     ]
    }
   ],
   "source": [
    "for firstWord in table:\n",
    "    for secondWord in table[firstWord]:\n",
    "        if table[firstWord][secondWord] > 10 and table[firstWord][secondWord] < 20:\n",
    "            print(firstWord, \"&\", secondWord, \",\", table[firstWord][secondWord])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aisle Bundle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Data Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge user, order and product info into one df\n",
    "order_aisle = pd.merge(pd.merge(train,prod,how='left',on='product_id'),\\\n",
    "                       aisles, on=\"aisle_id\", how=\"left\")\n",
    "user_order_aisle = pd.merge(order_aisle,orders,how='left',on='order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fresh_vegetables'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace whitespaces with \"_\"\n",
    "aisles_col = user_order_aisle['aisle']\n",
    "aisle_no_space =[]\n",
    "for aisle in aisles_col:\n",
    "    aisle = aisle.replace(' ','_')\n",
    "    aisle_no_space.append(aisle)\n",
    "\n",
    "# replace the original column with no_space one\n",
    "user_order_aisle.drop(['aisle'],axis=1)\n",
    "user_order_aisle['aisle'] = aisle_no_space\n",
    "user_order_aisle['aisle'][1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>aisles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>eggs fresh_vegetables spices_seasonings oils_v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>yogurt soy_lactosefree packaged_vegetables_fru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>breakfast_bakery cold_flu_allergy energy_grano...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>fresh_fruits salad_dressing_toppings prepared_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>refrigerated laundry air_fresheners_candles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id                                             aisles\n",
       "0         2  eggs fresh_vegetables spices_seasonings oils_v...\n",
       "1         3  yogurt soy_lactosefree packaged_vegetables_fru...\n",
       "2         4  breakfast_bakery cold_flu_allergy energy_grano...\n",
       "3         5  fresh_fruits salad_dressing_toppings prepared_...\n",
       "4         6        refrigerated laundry air_fresheners_candles"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregate all aisles by order id\n",
    "all_aisle = []\n",
    "for a_name in user_order_aisle.groupby('order_id')['aisle']:\n",
    "    all_aisle.append(' '.join(a_name[1]))\n",
    "\n",
    "# put the results into new df\n",
    "order_id2 = user_order_aisle.groupby('order_id')['aisle'].agg('count').index\n",
    "order_id_aisle = pd.DataFrame({'order_id':order_id2,'aisles':all_aisle})\n",
    "order_id_aisle.head()  ## take a glimpse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)Extract Bigrams (PySpark)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the df in PySpark format\n",
    "df2 = []\n",
    "index = 0\n",
    "for row in order_id_aisle['aisles']:\n",
    "    aisle_name = row.split(' ')\n",
    "    tup = (index, aisle_name)\n",
    "    df2.append(tup)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly split data into train (70%) and test (30%)\n",
    "random.shuffle(df2)\n",
    "train_df2 = df2[:2250411]\n",
    "test_df2 = df2[2250411:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to spark df\n",
    "spark = SparkSession.builder.appName(\"Bigram\").getOrCreate()\n",
    "\n",
    "# read 10,000 lines each time to reduce computation\n",
    "N2 = len(train_df2)//10000\n",
    "mod2 = len(train_df2) % 10000\n",
    "trainDF2 = spark.createDataFrame(df2[0:10000], ['id',\"aisle\"])\n",
    "\n",
    "for i in range(1,N2):\n",
    "    trainDF2_sub = spark.createDataFrame(train_df2[10000*i:10000*(i+1)], ['id',\"aisle\"])\n",
    "    traintDF2 = trainDF2.union(trainDF2_sub)\n",
    "\n",
    "# combine into one spark df \n",
    "trainDF2_sub = spark.createDataFrame(train_df2[10000*N2:len(train_df2)], ['id',\"aisle\"])\n",
    "trainDF2 = trainDF2.union(trainDF2_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect bigrams\n",
    "ngram2 = NGram(n=2, inputCol=\"aisle\", outputCol=\"bigrams\")\n",
    "ngram2_df = ngram2.transform(trainDF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count frequency\n",
    "bigrams2 = ngram2_df.toPandas()['bigrams']\n",
    "table2 = {}\n",
    "total2 = len(bigrams2)\n",
    "completion = 0\n",
    "for bigram in bigrams2:\n",
    "    for combination in bigram:\n",
    "        components = combination.split(' ')\n",
    "        key = components[0]\n",
    "        valKey = components[1]\n",
    "        if key in table2:\n",
    "            valueDict = table2[key]\n",
    "            if valKey in valueDict:\n",
    "                valueDict[valKey] = valueDict[valKey] + 1\n",
    "            else:\n",
    "                valueDict[valKey] = 1\n",
    "        else:\n",
    "            # create new value for key\n",
    "            valueDict =  {valKey: 1}\n",
    "            table2[key] = valueDict\n",
    "    completion += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fresh_vegetables & fresh_vegetables , 2839\n",
      "fresh_vegetables & fresh_fruits , 1183\n",
      "fresh_vegetables & yogurt , 201\n",
      "fresh_vegetables & packaged_vegetables_fruits , 778\n",
      "fresh_vegetables & packaged_cheese , 269\n",
      "fresh_vegetables & fresh_herbs , 305\n",
      "fresh_fruits & packaged_cheese , 282\n",
      "fresh_fruits & fresh_vegetables , 1339\n",
      "fresh_fruits & fresh_fruits , 2295\n",
      "fresh_fruits & water_seltzer_sparkling_water , 210\n",
      "fresh_fruits & milk , 307\n",
      "fresh_fruits & yogurt , 474\n",
      "fresh_fruits & soy_lactosefree , 239\n",
      "fresh_fruits & packaged_vegetables_fruits , 881\n",
      "packaged_vegetables_fruits & packaged_vegetables_fruits , 515\n",
      "packaged_vegetables_fruits & fresh_fruits , 818\n",
      "packaged_vegetables_fruits & fresh_vegetables , 826\n",
      "yogurt & yogurt , 1305\n",
      "yogurt & fresh_fruits , 415\n",
      "yogurt & fresh_vegetables , 268\n",
      "ice_cream_ice & ice_cream_ice , 358\n",
      "milk & fresh_fruits , 381\n",
      "packaged_cheese & fresh_fruits , 276\n",
      "packaged_cheese & packaged_cheese , 316\n",
      "packaged_cheese & fresh_vegetables , 266\n",
      "fresh_herbs & fresh_vegetables , 264\n",
      "water_seltzer_sparkling_water & water_seltzer_sparkling_water , 423\n",
      "water_seltzer_sparkling_water & fresh_fruits , 244\n",
      "chips_pretzels & chips_pretzels , 297\n",
      "energy_granola_bars & energy_granola_bars , 490\n",
      "soy_lactosefree & fresh_fruits , 252\n",
      "baby_food_formula & baby_food_formula , 572\n",
      "refrigerated & refrigerated , 282\n",
      "frozen_meals & frozen_meals , 339\n"
     ]
    }
   ],
   "source": [
    "# product combinations appears more than 200 times\n",
    "for firstWord in table2:\n",
    "    for secondWord in table2[firstWord]:\n",
    "        if table2[firstWord][secondWord] > 200:\n",
    "            print(firstWord, \"&\", secondWord, \",\", table2[firstWord][secondWord])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPureData(prodName):\n",
    "    \n",
    "    '''sort the bigram frequencies in descending order, \n",
    "       then return merely the corresponding product names in the same order'''\n",
    "    \n",
    "    if prodName not in table:\n",
    "        return []\n",
    "    sortedOringalList = sorted(table[prodName].items(), key=lambda x: x[1], reverse=True)\n",
    "#     print(sortedOringalList)\n",
    "    data = {}\n",
    "    for tp in sortedOringalList:\n",
    "        product = tp[0]\n",
    "        number = tp[1]\n",
    "        if number in data:\n",
    "            productList = data[number]\n",
    "            productList.append(product)\n",
    "        else:\n",
    "            productList = [product]\n",
    "        data[number] = productList\n",
    "#     print(data)\n",
    "#     print(\"==> Get pure data name:\")\n",
    "    pureData = data.values()\n",
    "#     print(pureData)\n",
    "    return list(pureData)\n",
    "\n",
    "def pickRecommendProds(pureData, numberOfRecommend):\n",
    "    \n",
    "    '''Pick certain number of products from the sorted product names'''\n",
    "    \n",
    "    recommendProds = []\n",
    "    for prods in pureData:\n",
    "        if len(prods) <= numberOfRecommend:\n",
    "            recommendProds += prods\n",
    "            numberOfRecommend -= len(prods)\n",
    "        else:\n",
    "            recommendProds += random.sample(prods, numberOfRecommend)\n",
    "            numberOfRecommend = 0\n",
    "\n",
    "        if numberOfRecommend == 0:\n",
    "            break\n",
    "    \n",
    "    return recommendProds\n",
    "\n",
    "# recommend products bought together with 'name'\n",
    "# name: the product to start with\n",
    "def getRecommend(name, numberOfRecommend):\n",
    "    \n",
    "    '''Recommend certain number of products bought after the given input name'''\n",
    "    \n",
    "    # numberOfRecommend = 10\n",
    "    recommendProducts = []\n",
    "    productName = name\n",
    "    index = 0\n",
    "\n",
    "    while (numberOfRecommend):\n",
    "#         print(\"->Target: \", productName)\n",
    "#         print(\"->numberOfRecommend: \", numberOfRecommend)\n",
    "#         print(\"->Index: \", index)\n",
    "        data = getPureData(productName)\n",
    "    #     print(\"Pure data:\", data)\n",
    "        intermediate = pickRecommendProds(data, numberOfRecommend)\n",
    "        recommendProducts += intermediate\n",
    "#         print(\"Recommend: \", recommendProducts)\n",
    "#         print(\"Recommend: \", recommendProducts)\n",
    "        if len(intermediate) == 0 and index == len(recommendProducts):\n",
    "            break\n",
    "        numberOfRecommend -= len(intermediate)\n",
    "        if numberOfRecommend > 0:\n",
    "#             print(\"Still left: \", numberOfRecommend)\n",
    "            productName = recommendProducts[index]\n",
    "            index += 1\n",
    "\n",
    "#         print(\"==================\")\n",
    "\n",
    "    return recommendProducts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reduced_Fat_2%_Milk', 'Semi-Sweet_Chocolate_Morsels', 'Clementines', 'Little_Bites_Blueberry_Muffin_Pouches', 'Crunchy_Cheese_Flavored_Snacks']\n"
     ]
    }
   ],
   "source": [
    "print(getRecommend(\"Chocolate_Sandwich_Cookies\", 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Semi-Sweet_Chocolate_Morsels', 'Crunchy_Cheese_Flavored_Snacks', 'Reduced_Fat_2%_Milk', 'Clementines', 'Ritz_Crackers', 'Little_Bites_Blueberry_Muffin_Pouches', 'Raspberries', 'All-Purpose_Flour', 'Organic_Half_&_Half', 'Restaurant_Style_Medium_Salsa', 'Classic_Seasoning_with_Lemon_Skillet_Crisp_Tilapia', \"Crunchy_Flamin'_Hot\", 'Fat_Free_Milk', '0%_Greek_Strained_Yogurt', 'Organic_Unsweetened_Vanilla_Almond_Milk']\n"
     ]
    }
   ],
   "source": [
    "print(getRecommend(\"Chocolate_Sandwich_Cookies\", 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestScore(test_data):\n",
    "    \n",
    "    scores = []\n",
    "\n",
    "    for order_info in test_data:\n",
    "        this_order = order_info[1]\n",
    "        order_len = len(this_order)\n",
    "        #print('order:', this_order)\n",
    "        #print('length of order', order_len)\n",
    "        i = 0\n",
    "        this_score = 0\n",
    "\n",
    "        while (i < order_len):\n",
    "            if this_order[i] in table:\n",
    "                # use original order length as the num of recommendation\n",
    "                recommends = getRecommend(this_order[i], order_len)\n",
    "                #print('====> recommends of ', this_order[i], \" : \", recommends)\n",
    "                laterProds = this_order[i:]\n",
    "                # check if the recommended products is included in order\n",
    "                for prod in laterProds:\n",
    "                    if prod in recommends:\n",
    "                        #print(\"-->\", prod)\n",
    "                        this_score += 1\n",
    "                i += 1\n",
    "            else:\n",
    "                # if the product is not trained in model, skip\n",
    "                i += 1\n",
    "                order_len -= 1\n",
    "\n",
    "        #print(this_score)\n",
    "        if not order_len == 0:\n",
    "            scores.append(this_score/order_len)\n",
    "        #print(scores)\n",
    "        \n",
    "    # return a list of predicted scores\n",
    "    return(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test Scores:  0.18265900066835283\n"
     ]
    }
   ],
   "source": [
    "scores = TestScore(test_df)\n",
    "print(\"Mean Test Scores: \", np.mean(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
